{
  "name": "MEX Project",
  "tagline": "Metadata for Machine Learning Experiments",
  "body": "**MEX** is an _open source_ initiative which aims at facilitating the sharing and data management of machine learning experiment outputs. Relying on Linked Data technologies, we provide a simple, flexible and lightweight platform to manage machine leaning metadata. In the following we introduce the sub-projects ([more info...](https://github.com/AKSW/mexproject/)).\r\n\r\n## [MEX Vocabulary](https://github.com/AKSW/mexproject/tree/master/vocabulary)\r\n\r\nMEX Vocabulary provides a free-format to export and share machine learning metadata, indifferent to existing workflow systems or frameworks. As major advantage, users can benefit of the ``mex format`` for further analysis and integrations with less effort ([more info...](https://github.com/AKSW/mexproject/tree/master/vocabulary)).\r\n\r\n## [LOG4MEX Library](https://github.com/AKSW/mexproject/tree/master/log4mex)\r\n\r\n**LOG4MEX** is a Java library ([javadoc](http://dne5.com/mex/documentation/log4mex/)) which aims at facilitating the ``data management`` for machine learning experiments, increasing the ``interoperability`` as well as adding ``provenance`` to the generated metadata ([more info...](https://github.com/AKSW/mexproject/tree/master/log4mex)).\r\n\r\n**Advantages**\r\n###\r\n* With a few lines of code, automatically generate metadata for your ML experiments at every run (code excerpt below).\r\n\r\n```java\r\nMyMEX mex = new MyMEX();\r\n...\r\nString ex1 = mex.Configuration().addExecution(EnumExecutionsType.OVERALL, EnumPhases.TRAIN);\r\nmex.Configuration().Execution(ex1).setStartDate(new Date());\r\nmex.Configuration().Execution(ex1).setAlgorithm(alg1);\r\n...\r\nmex.Configuration().Execution(ex1).setEndDate(new Date());\r\n...\r\n```\r\n\r\n* Never lose an experiment configuration and find the best results among thousands with a simple query!\r\n\r\n    PREFIX  mexcore:  <http://mex.aksw.org/mex-core#>\r\n    PREFIX  mexperf:  <http://mex.aksw.org/mex-perf#>\r\n    PREFIX  mexalgo:  <http://mex.aksw.org/mex-algo#>\r\n    PREFIX  prov:     <http://www.w3.org/ns/prov#>\r\n    PREFIX  rdfs:     <http://www.w3.org/2000/01/rdf-schema#>\r\n\r\n    SELECT DISTINCT ?ExecutionID ?Algorithm ?Performance ?fMeasure WHERE {\r\n      ?execution prov:used ?alg;\r\n                 prov:id ?ExecutionID.\r\n      ?Performance prov:wasGeneratedBy  ?execution.\r\n      ?Performance mexperf:f1Measure ?fMeasure.\r\n      ?alg a mexalgo:Algorithm.\r\n      ?alg rdfs:label ?Algorithm.\r\n    } \r\n    ORDER BY DESC (?fMeasure)\r\n    LIMIT 30\r\n\r\n* Analyse your experiment and related variables visually with Linked Data technologies. Compare your results with the state of the art and enter our leaderboard by sharing the metadata on the [WASOTA](http://cirola2000.cloudapp.net:3019/#/home).\r\n\r\n![rel](http://dne5.com/mex/imagens/mex_relations_lod.png)\r\n\r\n## [MEX Framework](https://github.com/AKSW/mexproject/tree/master/framework/src/main/java/org/aksw/mex/framework)\r\n\r\nWhat about annotating your machine learning code and generate ``mex output``? \r\n\r\n```java\r\n@ExperimentInfo(createdBy = \"Esteves\", email = \"esteves@informatik.uni-leipzig.de\", title = \"Weka Lib Example\", tags = {\"WEKA\",\"J48\", \"DecisionTable\", \"MEX\", \"Iris\"})\r\n@Hardware(cpu = \"Intel Core i7\", memory = \"8 GB\", hdType = \"SSD\")\r\n@SamplingMethod(klass = MEXEnum.EnumSamplingMethod.CrossValidation, trainSize = 0.8, testSize = 0.2, folds = 10)\r\npublic class Foo{\r\n  ...\r\n}\r\n```\r\nas easy as possible ([more info...](https://github.com/AKSW/mexproject/tree/master/framework/src/main/java/org/aksw/mex/framework)).\r\n\r\n```java\r\njava -cp /home/user/mexframework org.aksw.mex.framework.MetaGeneration -uc IrisWekaExample.java -out mymex01.ttl\r\n```\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}